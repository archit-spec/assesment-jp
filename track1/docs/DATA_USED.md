# Data Used (Track A: Repo-Specific Pretraining)

## 1) Repos and corpus paths

- `hyperswitch` (Rust)
  - Source repo: `https://github.com/juspay/hyperswitch.git`
  - Local corpus: `data/code_corpus_hyperswitch`
  - Metadata: `data/corpus_metadata_hyperswitch.json`
- `verl` (Python)
  - Source repo: `https://github.com/volcengine/verl.git`
  - Local corpus: `data/code_corpus_verl`
  - Metadata: `data/corpus_metadata_verl.json`

## 2) How files were filtered

Filtering is done in `data_preparation.py` and is repo-specific.

- Only language files were kept:
  - Hyperswitch: `.rs`
  - verl: `.py`
- Only main source prefixes were kept:
  - Hyperswitch: `crates/`
  - verl: `verl/`
- Excluded low-signal/noisy paths (examples): tests, docs, examples, build artifacts, scripts, experimental paths.
- Excluded empty files.
- Excluded generated files using header markers such as: `generated by`, `auto-generated`, `do not edit`, `@generated`.
- Size/length filters:
  - Hyperswitch: 25 to 4000 lines
  - verl: 20 to 3500 lines
- Structural signal requirement:
  - Rust: regex-based function/type counts
  - Python: AST-based function/class counts
  - Files with very low structure (`functions + types < 2`) were dropped.
- Final selection:
  - Files were scored by structural density and size (`quality_score`) and top files were selected.

## 3) Final corpus size

- Hyperswitch:
  - Files: `300`
  - Lines: `370,212`
  - Functions: `14,560`
  - Types: `11,856`
- verl:
  - Files: `214`
  - Lines: `74,295`
  - Functions: `2,335`
  - Types/classes: `328`

## 4) How train/val/test were formed

Two split modes were used in different runs:

- `file` split (older runs): split by file list, then tokenize chunks separately for train/val.
- `chunk` split (latest verl run): tokenize all text first, then split chunks into train/val/test.

Latest strong verl run used:

- `split_mode: chunk`
- `val_ratio: 0.08`
- `test_ratio: 0.02`
- `sequence_curriculum: [1024, 1536, 2048]`
- `eval_block_size: 2048`
- `learning_rate: 1e-3`
- `batch_size: 4`
- `grad_accum_steps: 2`

Metrics file:
- `results/track_a_verl_metrics_lr1e3_chunkcurr.json`

## 5) Why baseline perplexity changed across runs

Baseline is not directly comparable across all runs because evaluation setup changed:

- Different block sizes (`512` vs `1536/2048`)
- Different split mode (`file` vs `chunk`)
- Different filtered corpora (older verl corpus vs stricter cleaned verl corpus)

So values like `3.5`, `2.7`, and `2.6` came from different experimental setups, not from the exact same baseline protocol.

## 6) Track B/C external-source pipeline (pretraining skipped)

To focus on Track B (SFT) and Track C (retrieval), data can be generated with:

- Script: `generate_external_track_bc_data.py`
- Outputs:
  - `data/sft_train.json`, `data/sft_test.json`, `data/sft_all.json`
  - `data/retrieval_train.json`, `data/retrieval_test.json`, `data/retrieval_all.json`
  - `data/sft_data_card.json`, `data/retrieval_data_card.json`
  - `@beautifulMention.md`

External resources wired into this pipeline:

- Repos/gists:
  - `https://github.com/archit-athena/deepwiki-scripts`
  - `https://github.com/archit-athena/commits-training`
  - `https://gist.github.com/archit-spec/572bf2ff4ce37cdf4c5606b0d3083ef5`
  - `https://gist.github.com/archit-spec/b5cdcc71d8a2699b74e13481c924b783`
  - `https://gist.github.com/archit-spec/00053c2a3693500028388ebe3014e68a`
  - `https://gist.github.com/archit-spec/1983d1a2eddc130316d15bdc9d1bb13c`
  - `https://gist.github.com/archit-spec/8a59e09cfe2d6fff41c041ea7b78f292`
- Hugging Face datasets:
  - `archit11/hyperswitch-token-aware-cpt-fixed`
  - `archit11/deepwiki-16k`
  - `archit11/new2`
  - `archit11/hyperswitch-filenames`
  - `neulab/agent-data-collection` (config: `code_feedback`)

Notes:

- In environments without HF/network access, the script records source load failures in the data cards and falls back to local corpus records (`data/code_corpus_hyperswitch` by default) to still produce assignment-compatible Track B/C datasets.
