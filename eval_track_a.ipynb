{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd6044",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE_MODEL_ID    = \"Qwen/Qwen2.5-Coder-3B\"\n",
    "FINETUNED_MODEL_ID = \"archit11/qwen2.5-coder-3b-hyperswitch-track-a-merged\"\n",
    "DATASET_ID       = \"archit11/hyperswitch-code-corpus-track-a\"\n",
    "\n",
    "# Colab T4 safe: 1024 tokens/chunk, stride=512, 20 samples max\n",
    "MAX_LENGTH  = 1024\n",
    "STRIDE      = 512\n",
    "NUM_SAMPLES = 20   # number of dataset rows to use; reduce if still slow\n",
    "\n",
    "\n",
    "def free_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "\n",
    "\n",
    "def compute_perplexity(model, encodings, max_length, stride):\n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "    nlls = []\n",
    "    prev_end_loc = 0\n",
    "    for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(model.device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "        with torch.no_grad():\n",
    "            loss = model(input_ids, labels=target_ids).loss\n",
    "        nlls.append(loss.cpu())\n",
    "        prev_end_loc = end_loc\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "    return torch.exp(torch.stack(nlls).mean()).item()\n",
    "\n",
    "\n",
    "def load_model(model_id, device):\n",
    "    print(f\"  Loading {model_id}...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True,\n",
    "    ).to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    # Load dataset once\n",
    "    print(f\"Loading dataset {DATASET_ID}...\")\n",
    "    try:\n",
    "        dataset = load_dataset(DATASET_ID, split=\"validation\")\n",
    "    except Exception:\n",
    "        dataset = load_dataset(DATASET_ID, split=\"train\")\n",
    "    text_column = \"content\" if \"content\" in dataset.column_names else \"text\"\n",
    "    subset = dataset[text_column][:NUM_SAMPLES]\n",
    "    print(f\"Using {len(subset)} samples, column='{text_column}'\")\n",
    "\n",
    "    # Tokenize once (shared tokenizer — same vocab for both models)\n",
    "    print(\"Tokenizing...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL_ID, trust_remote_code=True)\n",
    "    encodings = tokenizer(\"\\n\\n\".join(subset), return_tensors=\"pt\")\n",
    "    print(f\"Sequence length: {encodings.input_ids.size(1)} tokens\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Base model\n",
    "    base_model = load_model(BASE_MODEL_ID, device)\n",
    "    results[\"Base\"] = compute_perplexity(base_model, encodings, MAX_LENGTH, STRIDE)\n",
    "    print(f\"Base perplexity: {results['Base']:.4f}\")\n",
    "    del base_model\n",
    "    free_memory()\n",
    "\n",
    "    # Fine-tuned model\n",
    "    ft_model = load_model(FINETUNED_MODEL_ID, device)\n",
    "    results[\"Fine-Tuned\"] = compute_perplexity(ft_model, encodings, MAX_LENGTH, STRIDE)\n",
    "    print(f\"Fine-tuned perplexity: {results['Fine-Tuned']:.4f}\")\n",
    "    del ft_model\n",
    "    free_memory()\n",
    "\n",
    "    # Summary\n",
    "    delta = results[\"Fine-Tuned\"] - results[\"Base\"]\n",
    "    pct = delta / results[\"Base\"] * 100\n",
    "    print(\"\\n--- Results ---\")\n",
    "    print(f\"{'Model':<15} {'Perplexity':>12}\")\n",
    "    print(\"-\" * 28)\n",
    "    print(f\"{'Base':<15} {results['Base']:>12.4f}\")\n",
    "    print(f\"{'Fine-Tuned':<15} {results['Fine-Tuned']:>12.4f}\")\n",
    "    print(f\"{'Δ':<15} {delta:>+12.4f}  ({pct:+.2f}%)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2xb1is361a",
   "source": "### Expected Results\n\n| Model | Perplexity | Δ |\n|-------|-----------|---|\n| Base (`Qwen2.5-Coder-3B`) | 2.0576 | – |\n| Fine-Tuned | **1.3954** | **-32.19% ↓** |",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "zr3gqqtckgd",
   "source": "# Track A – Perplexity Evaluation\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/archit-spec/assesment-jp/blob/main/eval_track_a.ipynb)\n\nEvaluates **baseline** (`Qwen/Qwen2.5-Coder-3B`) vs **fine-tuned** (`archit11/qwen2.5-coder-3b-hyperswitch-track-a-merged`) perplexity on the Hyperswitch code corpus.\n\n**Dataset:** [`archit11/hyperswitch-code-corpus-track-a`](https://huggingface.co/datasets/archit11/hyperswitch-code-corpus-track-a)\n\n### Install dependencies\n```bash\npip install transformers datasets torch tqdm accelerate\n```",
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}