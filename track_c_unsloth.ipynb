{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hr_bwy_C-Q-j"
   },
   "source": [
    "#  Track C â€“ Unsloth Embedding Fine-Tuning\n",
    "\n",
    "Fine-tune `unsloth/Qwen3-Embedding-0.6B` using **FastSentenceTransformer** for memory efficiency on Colab T4.\n",
    "\n",
    "### Why Unsloth?\n",
    "- **30% less VRAM**, fits 2x larger batch sizes.\n",
    "- Supports LoRA for embedding models.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“¦ Dataset: [`archit11/code-embedding-dataset`](https://huggingface.co/datasets/archit11/code-embedding-dataset)\n",
    "\n",
    "### ðŸ“Š Results (Best Run - 3 Epochs)\n",
    "\n",
    "| Metric | Baseline | Fine-Tuned | Î” |\n",
    "|--------|----------|------------|---|\n",
    "| **MRR@10** | 0.8840 | **0.9617** | **+0.0777 â†‘** |\n",
    "| **nDCG@10** | 0.9093 | **0.9710** | **+0.0617 â†‘** |\n",
    "| **Recall@10** | 0.9870 | **1.0000** | **+0.0130 â†‘** |\n",
    "\n",
    "> **Note**: Results based on 3 epochs, batch size 8, learning rate 2e-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YonGk_BJ-Q-l"
   },
   "outputs": [],
   "source": [
    "# Cell 1 â€“ Install Unsloth\n",
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    import torch; v = re.match(r'[\\d]{1,}\\.[\\d]{1,}', str(torch.__version__)).group(0)\n",
    "    xformers = 'xformers==' + {'2.10':'0.0.34','2.9':'0.0.33.post1','2.8':'0.0.32.post2'}.get(v, \"0.0.34\")\n",
    "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth_zoo bitsandbytes accelerate {xformers} peft trl triton unsloth\n",
    "!pip install transformers==4.56.2\n",
    "!pip install --no-deps trl==0.22.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452,
     "referenced_widgets": [
      "926ef1b33382408e91601bcd65bd2a06",
      "6c873fa05c2d4125b66109b39afca52f",
      "8ebab6f403fc4a189a9c7bb666868387",
      "b3bb798927af4ccbbb2b30b49137af79",
      "560c6fa8c2a64a2d88eafeb618401c60",
      "0ca14725abf94c4189bea1e103b29a11",
      "f076522911c1403ea9a96e193940e7e1",
      "f7f318a390ce4bd587e901e8df3e31d4",
      "e3b5947483bb4f96b7b87a90d5b218f0",
      "b9bcd43a078b4162af07d1c43c715c96",
      "b293abb7866a45adae342648b4b5c402",
      "f9d997d5f3784b87a7284563dd4a928a",
      "3f09041533524dc598e48dc96d0f260b",
      "739d1c5eb6df4d5dbafabc07e59160cb",
      "125673d4e33e46e084aba04768755480",
      "a47ad045f9364a87927ebdddd4fbe6e1",
      "465f0d4bb124481ea0d848bdcd7e0c91",
      "29cb0e9f7e424be092bf4ac5b1e84673",
      "f5e8cc38c15f45319c0bb5ea64b21337",
      "25759a94b3f4441b9e17bce1b6dbd4b7",
      "e768fa1fd69c48b3a568b834e17b461c",
      "a903198e7eed4fbf995c272f4735cba7",
      "e47a2eb7406d45b3baf4c03029b3805a",
      "a6194f26d890416895b9ff624e55ad29",
      "726fe1fc47764290abc0f87b0add35e8",
      "bc20402b2b3842acb71ab539f136715b",
      "34bd7f986a29478086af0ca50a093a2b",
      "dc38c88c5a554fdeb8887e5053b6effc",
      "4436600b86c449058153dab1411209fe",
      "5c705578f4f64bfbaab8844f598f689c",
      "f9efc1893476419b9940bbcbad95fa18",
      "38e7f960bebc42529efb51846b6771f7",
      "0448009fc39246dca8fc6b82ee2416cb",
      "28f04fe3b6fa4be5ba133ba9ae9b1d76",
      "fb2ea1677cd94a77ad97d0678a3f5e43",
      "47783589ca944e7897d8000c2ba4ae4a",
      "ef61d6f1568a4fc9b11fdac24f4552a4",
      "646ee81a7ac047e78bc7570172de9a3a",
      "80d8e1fd49c54dd987ec1085a91d481c",
      "d1227059b8e54fcabb3825672e74f20b",
      "264d5b83ec9440cdaa801f0451978f1c",
      "0d15a9d6aec94b489e00c5bed288708b",
      "4aff9ad0221c438a9bd8df003eda2c19",
      "6726f83e73b047e48c590a073ce49a97",
      "c88b3309ba03428eb05c435cf6c2b311",
      "8d4eb930cde94646824eeb5c14a9483a",
      "9463bb04fe364baebfa5e537f3e76378",
      "5575269ff4aa4a0498c3367569fb6630",
      "0ce98b49c3c84f41a01fe76ec360ac67",
      "43cce0db8f294bb48c0171a849674f31",
      "6501514341e34a949dff9d8a9192af2d",
      "b67b491c30de41ae9a992cfa094cf796",
      "f4dd683846fe4695802d32b0f560a39f",
      "8b6af761f795486ea1e131c4c2ef061c",
      "06876c90e05a4d91ab9d127fda3da0f7",
      "7d58705969494eabae20aa9270099afb",
      "5142596bcad54b93988e66d319667e75",
      "15417d427fa34506b2cc5b69f3927f51",
      "1537aa784bb1417d9af832f214afa909",
      "0c0dfb1c483945c59c3e38a21338a8e4",
      "807098e731ca4d1ca9a56929643fa4a7",
      "2612769df37547d79bfb86e4a4cbb934",
      "b13e38c83fba49ae89fc03d7a5820ac7",
      "6abef04a81c04998bb132ed9790d1ac0",
      "15fffb1212e247e9b7fb5b8b38bc0e3d",
      "0c5c2206dd1343a3a327abf8f3426229",
      "3f51e544c1ef444b97f11354753b0cea",
      "78eb3dd73bdc4b8389306b9f17e6f1d4",
      "a92ecf26b9554dd0b1a2944a75f4908b",
      "80940b8c915e4082b3dacbcc8dd128b1",
      "8cd1eda2252942b782f852ca8c793231",
      "131c9cb1ad5c4fe591d118d3d8485eaf",
      "13ac1cb8f8a74df88dc87e9bcd804cbf",
      "a63ae25cea0b4608a15c011142e9f720",
      "99e3d44cfdff4f8ab2db0814b2a2ef1a",
      "11695eb84fb94fd3b775e99a7ff3bf3a",
      "74740ee261894ddc838ea693937c929b",
      "516018f8175b47cd882a63cd34c4cfa8",
      "c134a64a42844969b552528235d0165f",
      "e95de7a599d74084a18d6946b53dcef6",
      "d597c16be25c46eda49cad13d43ad318",
      "baf2b3e7a72545acbe5ce28434a8dc3c",
      "9686d803e5f3421db3177a8be3aa9fb1",
      "50dbe5dbc9d3468faa7cf6039d11cc39",
      "7b19ed5a104a45f0aae3e75ce7029df8",
      "8e04d6fd05ca45008122b5ea0336b8ed",
      "1cd6e8446f79480ca913e2afa35f39ef",
      "f1ac2c0884b040439fb9d19ea23766d3"
     ]
    },
    "id": "MQS4VQcU-Q-m",
    "outputId": "cdb7afcc-25a1-445a-ecdc-248f1e66aac1"
   },
   "outputs": [],
   "source": [
    "# Cell 2 â€“ Load Model\n",
    "from unsloth import FastSentenceTransformer\n",
    "\n",
    "model = FastSentenceTransformer.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-Embedding-0.6B\",\n",
    "    max_seq_length = 2048,\n",
    "    full_finetuning = False,\n",
    ")\n",
    "\n",
    "model = FastSentenceTransformer.get_peft_model(\n",
    "    model,\n",
    "    r = 32,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = False,\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    "    task_type = \"FEATURE_EXTRACTION\"\n",
    ")\n",
    "print(\"âœ“ Unsloth embedding model loaded with LoRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zv9yiRDL-Q-m",
    "outputId": "f3ac4d21-9553-4817-8146-2d51f10cf00a"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# Ensure a fresh load of the dataset to get the original column names as per HuggingFace dataset card\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"archit11/code-embedding-dataset\")\n",
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"test\"] if \"test\" in ds else train_ds.select(range(len(train_ds) - 24, len(train_ds)))\n",
    "\n",
    "# Dataset already has anchor/positive; drop label and other cols that confuse the collator\n",
    "train_ds = train_ds.select_columns([\"anchor\", \"positive\"])\n",
    "test_ds = test_ds.select_columns([\"anchor\", \"positive\"])\n",
    "\n",
    "print(f\"Train: {len(train_ds)} | Columns: {train_ds.column_names}\")\n",
    "print(train_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQpQ_fcR-Q-m",
    "outputId": "a28cc968-a130-488b-d826-f3c875bce0b2"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import (\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    losses\n",
    ")\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from unsloth import is_bf16_supported\n",
    "\n",
    "loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model = model,\n",
    "    train_dataset = train_ds,\n",
    "    loss = loss,\n",
    "    args = SentenceTransformerTrainingArguments(\n",
    "        output_dir = \"output_track_c\",\n",
    "        num_train_epochs = 3,  # Best results from 3 epochs\n",
    "        per_device_train_batch_size = 16,  # T4 safe with Unsloth\n",
    "        gradient_accumulation_steps = 1,\n",
    "        learning_rate = 2e-5,\n",
    "        fp16 = not is_bf16_supported(),\n",
    "        bf16 = is_bf16_supported(),\n",
    "        logging_steps = 1,\n",
    "        warmup_ratio = 0.03,\n",
    "        report_to = \"none\",\n",
    "        lr_scheduler_type = \"constant_with_warmup\",\n",
    "        batch_sampler = BatchSamplers.NO_DUPLICATES, # Important for MNRL\n",
    "        # Prevent the data collator from looking for a 'label' column\n",
    "        label_names = [],\n",
    "    ),\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQadYEPa-Q-n"
   },
   "outputs": [],
   "source": [
    "# Cell 5 â€“ Save & Evaluate (Placeholder)\n",
    "model.save_pretrained(\"output_track_c\")\n",
    "print(\"âœ“ Model saved. See standard Track C notebook for evaluation logic.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "Track C â€“ Unsloth Embeddings",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
